{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae6d66b-1409-4b16-930d-8d5737021cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, os.path\n",
    "#import ogr, osr\n",
    "import time\n",
    "import sys\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import seaborn as sns\n",
    "\n",
    "import urllib\n",
    "import fiona\n",
    "import google_streetview.api\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import requests\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbb3853-a983-4e6c-ad68-5698069e9325",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import branca.colormap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd407dba-b714-429a-abc5-731f7365ec7a",
   "metadata": {},
   "source": [
    "# Import UrbanMind data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcac840-2f64-4a00-aa5b-090d8bd7fc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "UM = pd.read_csv('Data/UrbanMind_v2.csv') #import your own UM data from your local path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8bb363-104a-4f06-aac9-309474b16f7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Assuming your DataFrame is named UM\n",
    "UM = UM[UM['in_out'] == 'Outdoors']\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "UM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adb69e2-33dd-4584-ab09-adfb6fb88e68",
   "metadata": {},
   "source": [
    "# Access GoogleStreetView images based on GPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da01df7-4e44-47a6-9dbe-3d3eeb2ce878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep the user id, EMA id, latitude and longtitude of GPS point for the first user\n",
    "c = UM.reset_index(drop=True)[['newid','obsid','latitude','longitude']].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6a51cd-4286-4046-8f69-f3984e60fc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir='D:/NatCap Research/Wellcome Trust/Output/metadata2' # manually edit\n",
    "key='' #here insert your own Google API\n",
    "num=500 # the batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64acaa8-6c11-4015-a29f-38040e79ece3",
   "metadata": {},
   "outputs": [],
   "source": [
    "featureNum = len(c) \n",
    "batch = int(featureNum/num + 0.5)\n",
    "number = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3f2e46-093b-45cf-97e7-110bd39fa380",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## we will get the nearest GSV image based on the coordinate we input\n",
    "for b in range(batch):\n",
    "    # for each batch process num GSV site\n",
    "    start = b*num\n",
    "    end = (b+1)*num\n",
    "    if end > featureNum:\n",
    "        end = featureNum\n",
    "    \n",
    "    ouputTextFile = 'Pnt_start%s_end%s.txt'%(start,end)\n",
    "    ouputGSVinfoFile = os.path.join(outdir,ouputTextFile)\n",
    "    \n",
    "    if os.path.exists(ouputGSVinfoFile):\n",
    "        continue\n",
    "\n",
    "    time.sleep(1)\n",
    "    \n",
    "    with open(ouputGSVinfoFile, 'w') as panoInfoText:\n",
    "                \n",
    "        for i in c:\n",
    "            user_id = i[0]\n",
    "            assessment_time = i[1]\n",
    "            lat = i[2]\n",
    "            lon = i[3]\n",
    "            print(user_id, assessment_time, lat, lon)\n",
    "            urlAddress = r'https://maps.googleapis.com/maps/api/streetview/metadata?size=600x300&location=%s,%s&heading=-45&pitch=42&fov=110&source=outdoor&key=%s'%(lat, lon, key)\n",
    "            time.sleep(0.1)\n",
    "            if sys.version_info[0] == 2:\n",
    "                # from urllib2 import urlopen\n",
    "                import urllib\n",
    "                metaData = urllib.urlopen(urlAddress).read()\n",
    "\n",
    "            if sys.version_info[0] == 3:\n",
    "                import urllib.request\n",
    "                request = urllib.request.Request(urlAddress)\n",
    "                metaData = urllib.request.urlopen(request).read()\n",
    "\n",
    "            data = json.loads(metaData)\n",
    "            if data['status'] == 'NOT_FOUND': \n",
    "                print('The data is not existing')\n",
    "                continue\n",
    "            \n",
    "            if data['status'] == 'ZERO_RESULTS': \n",
    "                print('The data is not existing')\n",
    "                continue\n",
    "\n",
    "            panoDate = data['date']\n",
    "            panoId = data['pano_id']\n",
    "            panoLat = data['location']['lat']\n",
    "            panoLon = data['location']['lng']\n",
    "            number = number + 1\n",
    "\n",
    "            print ('Num: %s/%s, User ID: %s, assessment time: %s, the coordinate (%s,%s), panoId is: %s, panoDate is: %s'%(number, featureNum, user_id, assessment_time, panoLat,panoLon,panoId, panoDate))\n",
    "            lineTxt = 'userID: %s assessment: %s panoID: %s panoDate: %s longitude: %s latitude: %s\\n'%(user_id, assessment_time, panoId, panoDate, panoLon, panoLat)\n",
    "            panoInfoText.write(lineTxt)\n",
    "            \n",
    "    panoInfoText.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12db04bf-75b8-4871-8a66-11b60f620fb0",
   "metadata": {},
   "source": [
    "# Download GSV image and Calculate GVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2c5fdf-69b1-4179-ab0d-0a25422e424c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is where you want your meta data and Google Street View images output to\n",
    "root = 'D:/NatCap Research/Wellcome Trust/Output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a123817-04e8-4951-9fee-4ab3893f847e",
   "metadata": {},
   "outputs": [],
   "source": [
    "indir= os.path.join(root, 'metadata2')\n",
    "outdir = os.path.join(root, 'gsvimgs2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93c9ead-91e0-40b9-bae0-3e463d7785d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "\n",
    "processed_pano_ids = set()\n",
    "\n",
    "# list all the metadata and then get the lon, lat, date info to download the GSV images to your google drive\n",
    "for txt in os.listdir(indir):\n",
    "  txtfile = os.path.join(indir, txt)\n",
    "\n",
    "  lines = open(txtfile,\"r\")\n",
    "  pitch = 0\n",
    "\n",
    "  # loop all lines in the txt files\n",
    "  for idx,line in enumerate(lines):\n",
    "      metadata = line.split(\" \")\n",
    "#      userID = metadata[1]\n",
    "#      assessment = metadata[3]\n",
    "      panoID = metadata[5]\n",
    "      panoDate = metadata[7]\n",
    "      month = panoDate[-2:]\n",
    "      lon = metadata[9]\n",
    "      lat = metadata[11][:-1]\n",
    "\n",
    "      print('The lon, lat are:', lon, lat)\n",
    "\n",
    "      if panoID in processed_pano_ids:\n",
    "          print(f\"Skipping panoID {panoID} as it has already been processed.\")\n",
    "          continue\n",
    "\n",
    "    # Add the panoID to the set\n",
    "      processed_pano_ids.add(panoID)\n",
    "\n",
    "      headingArr = 360/6*np.array([0,1,2,3,4,5])\n",
    "\n",
    "      # calculate the green view index\n",
    "      greenPercent = 0.0\n",
    "\n",
    "      for heading in headingArr:\n",
    "          print (\"Heading is: \",heading)\n",
    "\n",
    "          # the name of the output image\n",
    "          imgName = r'%s - %s - %s - %s - %s.jpg'%(panoID, lon, lat, panoDate, heading)\n",
    "          mergedImgFile = os.path.join(outdir, imgName)\n",
    "          if os.path.exists(mergedImgFile): continue\n",
    "\n",
    "          # using different keys for different process, each key can only request 25,000 imgs every 24 hours\n",
    "          URL = \"http://maps.googleapis.com/maps/api/streetview?size=400x400&pano=%s&fov=60&heading=%d&pitch=%d&sensor=false&key=%s\"%(panoID, heading, pitch, key)\n",
    "          # let the code to pause by 1s, in order to not go over data limitation of Google quota\n",
    "          time.sleep(1)\n",
    "\n",
    "          response = requests.get(URL)\n",
    "          im = np.array(Image.open(io.BytesIO(response.content)))\n",
    "\n",
    "          img = Image.fromarray(im)\n",
    "          img.save(mergedImgFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737b04d7-9794-4eb0-b536-8570ddc1694b",
   "metadata": {},
   "source": [
    "# Semantic segmentation and Generate the Green View Index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c7d8fe-9e13-4ea9-ac8b-70bd71e70b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip show keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995332b2-8afa-4ba3-8fd0-cb63bfbfc923",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import zipfile\n",
    "import glob as glob\n",
    " \n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from matplotlib.patches import Rectangle\n",
    " \n",
    "import warnings\n",
    "import logging\n",
    "import absl\n",
    " \n",
    "# Filter absl warnings\n",
    "warnings.filterwarnings(\"ignore\", module=\"absl\")\n",
    " \n",
    "# Capture all warnings in the logging system\n",
    "logging.captureWarnings(True)\n",
    " \n",
    "# Set the absl logger level to 'error' to suppress warnings\n",
    "absl_logger = logging.getLogger(\"absl\")\n",
    "absl_logger.setLevel(logging.ERROR)\n",
    " \n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53546af0-8a6a-48da-ad94-e3cd0bef4959",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = hub.load('https://kaggle.com/models/google/hrnet/frameworks/TensorFlow2/variations/v2-w48/versions/1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cb2e8c-e2ac-46fc-9531-01ffba292420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path, target_size=(512, 512)):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Resize and normalize the image\n",
    "    resized_image = cv2.resize(image, target_size)\n",
    "    normalized_image = resized_image / 255.0  # Normalize to [0, 1]\n",
    "    input_tensor = np.expand_dims(normalized_image, axis=0)  # Add batch dimension\n",
    "    return image, input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88eb3bd7-3e61-4418-a13d-c0cf0bb4496e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_percentage(mask, total_pixels):\n",
    "    vegetation_pixels = np.sum(mask == 255)\n",
    "    percentage = (vegetation_pixels / total_pixels) * 100\n",
    "    return percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241d7e4c-a762-4038-be38-2b359300972f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is where you want your meta data and Google Street View images output to\n",
    "root = 'D:/NatCap Research/Wellcome Trust/Output'\n",
    "\n",
    "indir= os.path.join(root, 'metadata2')\n",
    "outdir = os.path.join(root, 'gsvimgs2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4723f44-e260-4d9c-9cc5-35fe40f12c31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "\n",
    "GreenViewTxtFile = os.path.join(outdir, 'Pnt_start0_end500.txt')\n",
    "# list all the metadata and then get the lon, lat, date info to download the GSV images to your google drive\n",
    "for txt in os.listdir(indir):\n",
    "    txtfile = os.path.join(indir, txt)\n",
    "    lines = open(txtfile,\"r\")\n",
    "    pitch = 0\n",
    "    \n",
    "    with open(GreenViewTxtFile,\"w\") as gvResTxt:\n",
    "    # loop all lines in the txt files\n",
    "        for idx,line in enumerate(lines):\n",
    "            metadata = line.split(\" \")\n",
    "            userID = metadata[1]\n",
    "            assessment = metadata[3]\n",
    "            panoID = metadata[5]\n",
    "            panoDate = metadata[7]\n",
    "            month = panoDate[-2:]\n",
    "            lon = metadata[9]\n",
    "            lat = metadata[11][:-1]\n",
    "\n",
    "            print('The lon, lat are:', lon, lat)\n",
    "\n",
    "            headingArr = 360/6*np.array([0,1,2,3,4,5])\n",
    "\n",
    "            # calculate the green view index\n",
    "            greenPercent = 0.0\n",
    "\n",
    "            for heading in headingArr:\n",
    "                print (\"Heading is: \",heading)\n",
    "\n",
    "                imgName = r'%s - %s - %s - %s - %s.jpg'%(panoID, lon, lat, panoDate, heading)\n",
    "                mergedImgFile = os.path.join(outdir, imgName)\n",
    "\n",
    "                original_image, input_tensor = preprocess_image(mergedImgFile)\n",
    "                output = model1(input_tensor)  # The output shape will be [1, height, width, num_classes]\n",
    "                segmentation_map = tf.argmax(output, axis=-1).numpy()[0]  # Convert to class labels\n",
    "    \n",
    "                tree_mask = (segmentation_map == 9).astype(np.uint8) * 255\n",
    "                grass_mask = (segmentation_map == 10).astype(np.uint8) * 255\n",
    "                \n",
    "                total_pixels = original_image.shape[0] * original_image.shape[1]\n",
    "                tree_percentage = calculate_percentage(tree_mask, total_pixels)\n",
    "                grass_percentage = calculate_percentage(grass_mask, total_pixels)\n",
    "                vegetation_percentage = tree_percentage+grass_percentage\n",
    "                greenPercent = greenPercent + vegetation_percentage\n",
    "\n",
    "            greenview = greenPercent/6.0\n",
    "            print('The green view index is:', greenview)\n",
    "\n",
    "            lineTxt = 'userID: %s obsID: %s panoID: %s panoDate: %s longitude: %s latitude: %s greenview: %s\\n'%(userID, assessment, panoID, panoDate, lon, lat, greenview)\n",
    "            gvResTxt.write(lineTxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f038335-34c3-4b07-a429-140c7ec778bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "GreenViewTxtFile = os.path.join(outdir, 'Pnt_start0_end500.txt')\n",
    "\n",
    "lines = open(GreenViewTxtFile,\"r\")\n",
    "newidList = []\n",
    "obsidList = []\n",
    "panoIdList = []\n",
    "panoDateList = []\n",
    "panoLonList = []\n",
    "panoLatList = []\n",
    "greenViewList = []\n",
    "\n",
    "for line in lines:\n",
    "    elem = line.split(' ')\n",
    "    newidList.append(elem[1])\n",
    "    obsidList.append(elem[3])\n",
    "    panoIdList.append(elem[5])\n",
    "    panoDateList.append(elem[7])\n",
    "    panoLonList.append(elem[9])\n",
    "    panoLatList.append(elem[11])\n",
    "    greenViewList.append(elem[13][:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa90cacf-34ef-40ba-b8dc-8dd9a7d35446",
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate a dataframe with user_ID, EMA ID, panoID for GSV, data when GSV was taken, latitude, longitude, and GVI\n",
    "GVI = pd.DataFrame({'newid': newidList, 'obsid': obsidList, 'panoId': panoIdList, 'panoDate': panoDateList, 'panoLon': panoLonList, \n",
    "                   'panoLat': panoLatList, 'GVI': greenViewList})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6153bb3-0611-4876-9e33-4f57a83bd6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "GVI.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cf3695-eb93-4d0b-8ed2-bb8db3e84952",
   "metadata": {},
   "outputs": [],
   "source": [
    "GVI.to_csv('D:/NatCap Research/Wellcome Trust/Green space measurement result/GSV_GVI_extra.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb68677d-74fb-4b02-b316-68a2b686d94e",
   "metadata": {},
   "source": [
    "# Some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10557807-6bba-4066-a8b1-2b55dbba66dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = r'D:\\NatCap Research\\Wellcome Trust\\Output\\gsvimgs2\\_6xhPKvJq7EraoDtfEM5Zw - -4.547079109495603 - 50.83117052888723 - 2022-09 - 180.0.jpg' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21eea297-5504-4204-a90f-4c272c0b1873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "original_image, input_tensor = preprocess_image(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85de849-d429-46e2-b52b-bd2d93e88dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform inference\n",
    "output = model1(input_tensor)  # The output shape will be [1, height, width, num_classes]\n",
    "segmentation_map = tf.argmax(output, axis=-1).numpy()[0]  # Convert to class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677a7ed1-efe4-444c-968c-51d018173e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_vegetation(segmentation_map, vegetation_classes):\n",
    "    mask = np.zeros_like(segmentation_map)\n",
    "    for class_id in vegetation_classes:\n",
    "        mask[segmentation_map == class_id] = class_id\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3ab41c-7f83-4c93-a855-096a5a9d039a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter vegetation classes (Tree: 21, Terrain: 22)\n",
    "vegetation_classes = [9, 10]\n",
    "vegetation_mask = filter_vegetation(segmentation_map, vegetation_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14c853d-c0a9-45c7-98bc-fcba4d2f1a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define colors for each class\n",
    "class_colors = {\n",
    "    9: [34, 139, 34],  # Forest green for trees\n",
    "    10: [124, 252, 0] # Lawn green for grass\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1a92f4-7154-41eb-a083-160c060e034f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_color_map(segmentation_map, class_colors):\n",
    "    height, width = segmentation_map.shape\n",
    "    color_map = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "    for class_id, color in class_colors.items():\n",
    "        color_map[segmentation_map == class_id] = color\n",
    "    return color_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142e4033-daa5-49ff-8756-7c81f117696d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply color map to the vegetation mask\n",
    "colored_segmentation = apply_color_map(vegetation_mask, class_colors)\n",
    "\n",
    "# Plot the original image and the segmentation mask\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Original Image\")\n",
    "plt.imshow(original_image)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Vegetation Segmentation\")\n",
    "plt.imshow(colored_segmentation)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
