{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "## Load shp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory:\n",
      " d:\\natcap\\urban-cooling-health\\code\n",
      "Parent folder:\n",
      " d:\\natcap\\urban-cooling-health\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define file path\n",
    "file1_path = r\"G:/Shared drives/Wellcome Trust Project Data/0_source_data/GiGL land use data/GiGL_Trees_font_point/GiGL_GLATrees_Pre2023.shp\"\n",
    "file2_path = r\"G:/Shared drives/Wellcome Trust Project Data/0_source_data/GiGL land use data/GiGL_Trees_font_point/GiGL_GLATrees_2023-24.shp\"\n",
    "\n",
    "# Define output path\n",
    "current_path = os.getcwd()\n",
    "print(\"Current working directory:\\n\", current_path)\n",
    "\n",
    "parent_folder = os.path.dirname(current_path)\n",
    "print(\"Parent folder:\\n\", parent_folder)\n",
    "\n",
    "##\n",
    "wd_shp = r'G:\\Shared drives\\Wellcome Trust Project Data\\1_preprocess\\UrbanCoolingModel'\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Where to save\n",
    "out_dir = Path(parent_folder) / \"data\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# # Read the spatial data one by one\n",
    "# d = gpd.read_file(file1_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load all the saved data\n",
    "\n",
    "f1 = os.path.join(parent_folder, \"data\", os.path.basename(file1_path).replace('.shp', '') + \"_risk_2050.shp\"); print(f1)\n",
    "f2 = os.path.join(parent_folder, \"data\", os.path.basename(file2_path).replace('.shp', '') + \"_risk_2050.shp\"); print(f2)\n",
    "\n",
    "\n",
    "# Read the spatial data\n",
    "tree_risk_layer1 = gpd.read_file(f1, engine=\"pyogrio\")\n",
    "tree_risk_layer2 = gpd.read_file(f2, engine=\"pyogrio\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combine shp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 1050054 features to d:\\natcap\\urban-cooling-health\\data\\GiGL_GLATrees_at_risk_2050_merged.gpkg (layer='GiGL_GLATrees_at_risk_2050_merged')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# You already have:\n",
    "# f1, f2\n",
    "# tree_risk_layer1 = gpd.read_file(f1, engine=\"pyogrio\")\n",
    "# tree_risk_layer2 = gpd.read_file(f2, engine=\"pyogrio\")\n",
    "\n",
    "g1 = tree_risk_layer1.copy()\n",
    "g2 = tree_risk_layer2.copy()\n",
    "\n",
    "# Tag source\n",
    "g1[\"source_file\"] = Path(f1).name\n",
    "g2[\"source_file\"] = Path(f2).name\n",
    "\n",
    "# Pick a target CRS (prefer the first non-None)\n",
    "target_crs = g1.crs or g2.crs\n",
    "\n",
    "# Align CRS\n",
    "def _align_crs(g, target):\n",
    "    if target is None:\n",
    "        return g\n",
    "    if g.crs is None:\n",
    "        return g.set_crs(target)\n",
    "    if g.crs != target:\n",
    "        return g.to_crs(target)\n",
    "    return g\n",
    "\n",
    "g1 = _align_crs(g1, target_crs)\n",
    "g2 = _align_crs(g2, target_crs)\n",
    "\n",
    "# Union schema (keep geometry last)\n",
    "all_cols = [c for c in sorted(set(g1.columns) | set(g2.columns)) if c != \"geometry\"] + [\"geometry\"]\n",
    "g1 = gpd.GeoDataFrame(g1.reindex(columns=all_cols), geometry=\"geometry\", crs=target_crs)\n",
    "g2 = gpd.GeoDataFrame(g2.reindex(columns=all_cols), geometry=\"geometry\", crs=target_crs)\n",
    "\n",
    "# Fix invalid geometries (best effort)\n",
    "try:\n",
    "    from shapely import make_valid\n",
    "    g1[\"geometry\"] = make_valid(g1.geometry)\n",
    "    g2[\"geometry\"] = make_valid(g2.geometry)\n",
    "except Exception:\n",
    "    g1[\"geometry\"] = g1.buffer(0)\n",
    "    g2[\"geometry\"] = g2.buffer(0)\n",
    "\n",
    "# Drop empty/null geoms\n",
    "g1 = g1[g1.geometry.notnull() & ~g1.geometry.is_empty]\n",
    "g2 = g2[g2.geometry.notnull() & ~g2.geometry.is_empty]\n",
    "\n",
    "# Concatenate\n",
    "combined = gpd.GeoDataFrame(\n",
    "    pd.concat([g1, g2], ignore_index=True, sort=False),\n",
    "    geometry=\"geometry\",\n",
    "    crs=target_crs\n",
    ")\n",
    "\n",
    "# (Optional) drop exact duplicates (including geometry)\n",
    "# combined = combined.drop_duplicates(subset=[c for c in combined.columns if c != \"geometry\"] + [\"geometry\"])\n",
    "\n",
    "# Save\n",
    "out_path = os.path.join(parent_folder, \"data\", \"GiGL_GLATrees_at_risk_2050_merged.gpkg\")\n",
    "layer_name = Path(out_path).stem  # \"GiGL_GLATrees_at_risk_2050_merged\"\n",
    "\n",
    "combined.to_file(out_path, driver=\"GPKG\", layer=layer_name)\n",
    "print(f\"Wrote {len(combined)} features to {out_path} (layer='{layer_name}')\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year year_label   count  percent\n",
      "0  2050       2050  657622    62.63\n",
      "1  <NA>    Unknown  392432    37.37\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- make 'year' sortable & consistent ---\n",
    "if 'year' not in combined.columns:\n",
    "    raise KeyError(\"'year' column not found in combined\")\n",
    "\n",
    "# if it's datetime-like, grab the year; else coerce to numeric\n",
    "if pd.api.types.is_datetime64_any_dtype(combined['year']):\n",
    "    combined['year'] = combined['year'].dt.year.astype('Int64')\n",
    "else:\n",
    "    combined['year'] = pd.to_numeric(combined['year'], errors='coerce').astype('Int64')\n",
    "\n",
    "# --- summarize ---\n",
    "summary = (\n",
    "    combined\n",
    "    .groupby('year', dropna=False)\n",
    "    .size()\n",
    "    .rename('count')\n",
    "    .reset_index()\n",
    "    .sort_values('year', na_position='last')\n",
    ")\n",
    "\n",
    "total_n = len(combined)\n",
    "summary['percent'] = (summary['count'] / total_n * 100).round(2)\n",
    "\n",
    "# for display, keep a nice label while preserving numeric 'year'\n",
    "summary['year_label'] = summary['year'].astype(str).replace('<NA>', 'Unknown')\n",
    "\n",
    "print(summary[['year', 'year_label', 'count', 'percent']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1m grid shp to 10m grid\n",
    "\n",
    "Turn the 1 m × 1 m grid to a 10 m × 10 m grid -- snap cells to a 10 m lattice and aggregate. This avoids creating 100 overlapping squares per tile.\n",
    "\n",
    "* **Warning**: this will take a long time to run! Uncomment this block if update is needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 777007 tiles to d:\\natcap\\urban-cooling-health\\data\\GiGL_GLATrees_at_risk_2050_merged_tiles10.gpkg (layer='tiles10')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "\n",
    "gdf = combined.copy()\n",
    "\n",
    "# 0) Ensure CRS is metric (meters)\n",
    "if gdf.crs is None or not gdf.crs.is_projected:\n",
    "    raise ValueError(\"Project to a metric CRS first (e.g., EPSG:5070 or UTM).\")\n",
    "\n",
    "# 1) Define 10 m grid origin (snap to a multiple of 10 m)\n",
    "cell = 10.0\n",
    "xmin, ymin, xmax, ymax = gdf.total_bounds\n",
    "x0 = np.floor(xmin / cell) * cell\n",
    "y0 = np.floor(ymin / cell) * cell\n",
    "\n",
    "# 2) Compute grid indices for each 1 m cell using its lower-left corner\n",
    "b = gdf.geometry.bounds  # DataFrame with minx, miny, maxx, maxy\n",
    "i = np.floor((b[\"minx\"] - x0) / cell).astype(\"int64\")\n",
    "j = np.floor((b[\"miny\"] - y0) / cell).astype(\"int64\")\n",
    "gdf[\"i\"] = i\n",
    "gdf[\"j\"] = j\n",
    "\n",
    "# 3) Build unique 10 m tiles as polygons\n",
    "keys = gdf[[\"i\", \"j\"]].drop_duplicates().reset_index(drop=True)\n",
    "xs = x0 + keys[\"i\"].to_numpy() * cell\n",
    "ys = y0 + keys[\"j\"].to_numpy() * cell\n",
    "geoms = [box(x, y, x + cell, y + cell) for x, y in zip(xs, ys)]\n",
    "tiles10 = gpd.GeoDataFrame(keys, geometry=geoms, crs=gdf.crs)\n",
    "\n",
    "# 4) (Optional) carry aggregations to 10 m grid\n",
    "# Count how many 1 m cells fell into each 10 m tile (0–100, typically <=100 if partial coverage)\n",
    "counts = gdf.groupby([\"i\", \"j\"]).size().rename(\"n_cells\").reset_index()\n",
    "tiles10 = tiles10.merge(counts, on=[\"i\", \"j\"], how=\"left\")\n",
    "\n",
    "# Example: majority year per 10 m tile (if you have a 'year' column)\n",
    "if \"year\" in gdf.columns:\n",
    "    per_year = gdf.groupby([\"i\", \"j\", \"year\"]).size().rename(\"n\").reset_index()\n",
    "    idx = per_year.groupby([\"i\", \"j\"])[\"n\"].idxmax()\n",
    "    majority_year = per_year.loc[idx, [\"i\", \"j\", \"year\"]]\n",
    "    tiles10 = tiles10.merge(majority_year, on=[\"i\", \"j\"], how=\"left\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- Best option: GeoPackage ---\n",
    "gpkg_path = out_dir / \"GiGL_GLATrees_at_risk_2050_merged_tiles10.gpkg\"\n",
    "layer_name = \"tiles10\"\n",
    "\n",
    "# keep grid keys as ints\n",
    "t10 = tiles10.copy()\n",
    "for c in (\"i\", \"j\"):\n",
    "    if c in t10.columns:\n",
    "        t10[c] = t10[c].astype(\"int64\")\n",
    "\n",
    "t10.to_file(gpkg_path, driver=\"GPKG\", layer=layer_name)  # engine=\"pyogrio\" also OK\n",
    "print(f\"Wrote {len(t10)} tiles to {gpkg_path} (layer='{layer_name}')\")\n",
    "\n",
    "# --- (Optional) Shapefile (use short field names, 32-bit ints) ---\n",
    "# shp_path = out_dir / \"tiles10_shp\" / \"tiles10.shp\"\n",
    "# (out_dir / \"tiles10_shp\").mkdir(exist_ok=True)\n",
    "# t_shp = t10.copy()\n",
    "# for c in (\"i\", \"j\"):\n",
    "#     if c in t_shp.columns:\n",
    "#         t_shp[c] = t_shp[c].astype(\"int32\")\n",
    "# t_shp.to_file(shp_path, driver=\"ESRI Shapefile\")\n",
    "# print(f\"Also wrote Shapefile to {shp_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ↓"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ↓"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ↓↓ Start from here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate lc scenario - tree at risk\n",
    "\n",
    "* **Load data and process from here!** if only to update lc scenario raster\n",
    "* Pick one of the land cover inputs data\n",
    "\n",
    "only changes LC pixels that (a) overlap the risk polygons and (b) are currently one of your tree codes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.features import rasterize\n",
    "\n",
    "\n",
    "## Load shapefile with tree cover will be at risk or loss\n",
    "shp_tree_risk = out_dir / \"GiGL_GLATrees_at_risk_2050_merged_tiles10.gpkg\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### land cover option 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## land cover data\n",
    "lc_input = r\"G:\\Shared drives\\Wellcome Trust Project Data\\1_preprocess\\UrbanCoolingModel\\EP_preliminary_tests\\clipped_lulc\\UKECH\\LCM2023_London_10m_clip2aoi_tcc24.tif\"\n",
    "\n",
    "tree_cover_code = [1, 2, 100]\n",
    "after_risk_lc_code = 4  # 4: 'Improved Grassland',\n",
    "\n",
    "# Define labels\n",
    "land_cover_labels = {\n",
    "    1: 'Deciduous woodland',\n",
    "    2: 'Coniferous woodland',\n",
    "    3: 'Arable',\n",
    "    4: 'Improved Grassland',\n",
    "    5: 'Neutral Grassland',\n",
    "    6: 'Calcareous Grassland',\n",
    "    7: 'Acid grassland',\n",
    "    8: 'Fen, Marsh, and Swamp',\n",
    "    9: 'Heather',\n",
    "    10: 'Heather grassland',\n",
    "    11: 'Bog',\n",
    "    12: 'Inland Rock',\n",
    "    13: 'Saltwater',\n",
    "    14: 'Freshwater',\n",
    "    15: 'Supralittoral Rock',\n",
    "    16: 'Supralittoral Sediment',\n",
    "    17: 'Littoral Rock',\n",
    "    18: 'Littoral Sediment',\n",
    "    19: 'Saltmarsh',\n",
    "    20: 'Urban',\n",
    "    21: 'Suburban',\n",
    "    100: 'Tree canopy'\n",
    "}\n",
    "\n",
    "\n",
    "# ## clip raster to AOI -------------------------------------------------------------------\n",
    "# aoi_shapefile = os.path.join(wd_shp, \"London_Ward_aoi_prj.shp\") \n",
    "# # Load administrative boundaries\n",
    "# aoi = gpd.read_file(aoi_shapefile)\n",
    "\n",
    "\n",
    "# # load function to use in notebook\n",
    "# from function_clip_raster_to_aoi import clip_raster_to_aoi\n",
    "\n",
    "\n",
    "# ## clip \n",
    "# # Output path (optional)\n",
    "# lc_clipped_tif = lc_input.replace(\".tif\", \"_clip2aoi.tif\")\n",
    "\n",
    "# filled_arr, filled_transform, filled_profile = clip_raster_to_aoi(\n",
    "#     raster_path=lc_input,\n",
    "#     aoi=aoi_shapefile,  # or pass your GeoDataFrame\n",
    "#     out_path=lc_clipped_tif,\n",
    "#     replace_nodata_with=0,     # convert 255/nodata -> 0\n",
    "#     keep_nodata_tag=False      # keep False so 0 is treated as a real class\n",
    "# )\n",
    "\n",
    "# print(\"Done. Saved to:\\n\\t\", lc_clipped_tif)\n",
    "# print(np.unique(filled_arr[~np.isnan(filled_arr)]))  # check valid classes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ## update land cover input data to the clipped raster ---------------------------------\n",
    "# lc_input = lc_clipped_tif  # Use the clipped raster as input\n",
    "\n",
    "\n",
    "lc_output = lc_input.replace(\".tif\", \"_scenario3_TreeRisk.tif\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### land cover option 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- File Paths ---\n",
    "# lc_input = r\"G:\\Shared drives\\Wellcome Trust Project Data\\1_preprocess\\UrbanCoolingModel\\ESA_WorldCover_10m_2021_v200_Mosaic_Mask_proj.tif\"\n",
    "# lc_output = lc_input.replace(\".tif\", \"_scenario3_TreeRisk.tif\")\n",
    "\n",
    "# tree_cover_code = 1      # ESA WorldCover: Tree cover\n",
    "# after_risk_lc_code = 3   # 3: 'Grassland',\n",
    "\n",
    "# # Define labels\n",
    "# land_cover_labels = {\n",
    "#     1: 'Tree cover',\n",
    "#     2: 'Shrubland',\n",
    "#     3: 'Grassland',\n",
    "#     4: 'Cropland',\n",
    "#     5: 'Built-up',\n",
    "#     6: \"Bare / sparse vegetation\",\n",
    "#     7: \"Snow and ice\",\n",
    "#     8: \"Permanent water bodies\",\n",
    "#     9: \"Herbaceous wetland\",\n",
    "#     10: \"Moss and lichen\"\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generate lc scenario "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated land cover raster saved at: G:\\Shared drives\\Wellcome Trust Project Data\\1_preprocess\\UrbanCoolingModel\\EP_preliminary_tests\\clipped_lulc\\UKECH\\LCM2023_London_10m_clip2aoi_tcc24_scenario3_TreeRisk.tif\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ensure output folder exists\n",
    "Path(os.path.dirname(lc_output)).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- Load and filter polygons ---\n",
    "tree_cover_at_risk = gpd.read_file(shp_tree_risk)\n",
    "## Filter the tree cover data with year = 2050, which indicate these trees will be at risk by 2050\n",
    "tree_cover_at_risk = tree_cover_at_risk[tree_cover_at_risk[\"year\"].isin([2050])]\n",
    "tree_cover_at_risk = tree_cover_at_risk[\n",
    "    tree_cover_at_risk.geometry.notna() & ~tree_cover_at_risk.geometry.is_empty\n",
    "]\n",
    "\n",
    "# --- Read raster ---\n",
    "with rasterio.open(lc_input) as src:\n",
    "    meta      = src.meta.copy()\n",
    "    transform = src.transform\n",
    "    lc_crs    = src.crs\n",
    "    src_nodata = src.nodata\n",
    "    arr       = src.read(1)  # 2D array of land cover codes\n",
    "\n",
    "\n",
    "# Reproject polygons to raster CRS if needed\n",
    "if tree_cover_at_risk.crs and (tree_cover_at_risk.crs != lc_crs):\n",
    "    tree_cover_at_risk = tree_cover_at_risk.to_crs(lc_crs)\n",
    "\n",
    "\n",
    "# --- Rasterize risk polygons to a mask (1 = at risk) ---\n",
    "shape_mask = rasterize(\n",
    "    [(geom, 1) for geom in tree_cover_at_risk.geometry],\n",
    "    out_shape=arr.shape,\n",
    "    transform=transform,\n",
    "    fill=0,\n",
    "    dtype=\"uint8\",\n",
    "    # all_touched=True,  # uncomment if you want a slightly more inclusive burn-in\n",
    ")\n",
    "\n",
    "# --- Build masks ---\n",
    "valid_mask = np.ones_like(arr, dtype=bool)\n",
    "if src_nodata is not None:\n",
    "    valid_mask &= (arr != src_nodata)\n",
    "\n",
    "# If LC==0 is background you want to preserve, keep it out of edits:\n",
    "valid_mask &= (arr != 0)\n",
    "\n",
    "# Only modify cells that are both \"at risk\" and currently a tree class\n",
    "tree_mask = np.isin(arr, tree_cover_code)\n",
    "target_mask = (shape_mask == 1) & tree_mask & valid_mask\n",
    "\n",
    "# --- Apply scenario ---\n",
    "remapped = arr.copy()\n",
    "remapped[target_mask] = after_risk_lc_code\n",
    "\n",
    "# --- Save updated raster ---\n",
    "meta_out = meta.copy()\n",
    "# Keep original dtype unless you explicitly want uint8\n",
    "meta_out.update(\n",
    "    dtype=remapped.dtype,\n",
    "    compress=\"lzw\",\n",
    "    nodata=0                # <-- change from src_nodata to 0\n",
    ")\n",
    "\n",
    "with rasterio.open(lc_output, \"w\", **meta_out) as dst:\n",
    "    dst.write(remapped, 1)\n",
    "\n",
    "print(f\"Updated land cover raster saved at: {lc_output}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lc change summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Class proportions BEFORE scenario ===\n",
      " class_code                  label   count  proportion  percent     area_m2  area_ha  area_km2\n",
      "          1     Deciduous woodland   81608    0.005117    0.512   8160800.0   816.08      8.16\n",
      "          2    Coniferous woodland   11848    0.000743    0.074   1184800.0   118.48      1.18\n",
      "          3                 Arable  570469    0.035773    3.577  57046900.0  5704.69     57.05\n",
      "          4     Improved Grassland 2814783    0.176510   17.651 281478300.0 28147.83    281.48\n",
      "          5      Neutral Grassland      10    0.000001    0.000      1000.0     0.10      0.00\n",
      "          6   Calcareous Grassland   41369    0.002594    0.259   4136900.0   413.69      4.14\n",
      "          8  Fen, Marsh, and Swamp   31479    0.001974    0.197   3147900.0   314.79      3.15\n",
      "          9                Heather     906    0.000057    0.006     90600.0     9.06      0.09\n",
      "         10      Heather grassland    4781    0.000300    0.030    478100.0    47.81      0.48\n",
      "         12            Inland Rock   12868    0.000807    0.081   1286800.0   128.68      1.29\n",
      "         13              Saltwater   10999    0.000690    0.069   1099900.0   109.99      1.10\n",
      "         14             Freshwater  326678    0.020485    2.049  32667800.0  3266.78     32.67\n",
      "         16 Supralittoral Sediment     412    0.000026    0.003     41200.0     4.12      0.04\n",
      "         18      Littoral Sediment    2067    0.000130    0.013    206700.0    20.67      0.21\n",
      "         19              Saltmarsh    8708    0.000546    0.055    870800.0    87.08      0.87\n",
      "         20                  Urban 4911131    0.307969   30.797 491113100.0 49111.31    491.11\n",
      "         21               Suburban 4005332    0.251167   25.117 400533200.0 40053.32    400.53\n",
      "        100            Tree canopy 3111410    0.195111   19.511 311141000.0 31114.10    311.14\n",
      "\n",
      "=== Class proportions AFTER scenario ===\n",
      " class_code                  label   count  proportion  percent     area_m2  area_ha  area_km2\n",
      "          1     Deciduous woodland   80134    0.005025    0.503   8013400.0   801.34      8.01\n",
      "          2    Coniferous woodland   11603    0.000728    0.073   1160300.0   116.03      1.16\n",
      "          3                 Arable  570469    0.035773    3.577  57046900.0  5704.69     57.05\n",
      "          4     Improved Grassland 3060925    0.191945   19.195 306092500.0 30609.25    306.09\n",
      "          5      Neutral Grassland      10    0.000001    0.000      1000.0     0.10      0.00\n",
      "          6   Calcareous Grassland   41369    0.002594    0.259   4136900.0   413.69      4.14\n",
      "          8  Fen, Marsh, and Swamp   31479    0.001974    0.197   3147900.0   314.79      3.15\n",
      "          9                Heather     906    0.000057    0.006     90600.0     9.06      0.09\n",
      "         10      Heather grassland    4781    0.000300    0.030    478100.0    47.81      0.48\n",
      "         12            Inland Rock   12868    0.000807    0.081   1286800.0   128.68      1.29\n",
      "         13              Saltwater   10999    0.000690    0.069   1099900.0   109.99      1.10\n",
      "         14             Freshwater  326678    0.020485    2.049  32667800.0  3266.78     32.67\n",
      "         16 Supralittoral Sediment     412    0.000026    0.003     41200.0     4.12      0.04\n",
      "         18      Littoral Sediment    2067    0.000130    0.013    206700.0    20.67      0.21\n",
      "         19              Saltmarsh    8708    0.000546    0.055    870800.0    87.08      0.87\n",
      "         20                  Urban 4911131    0.307969   30.797 491113100.0 49111.31    491.11\n",
      "         21               Suburban 4005332    0.251167   25.117 400533200.0 40053.32    400.53\n",
      "        100            Tree canopy 2866987    0.179784   17.978 286698700.0 28669.87    286.70\n",
      "\n",
      "Saved summaries:\n",
      "- G:\\Shared drives\\Wellcome Trust Project Data\\1_preprocess\\UrbanCoolingModel\\EP_preliminary_tests\\clipped_lulc\\UKECH\\LCM2023_London_10m_clip2aoi_tcc24_scenario3_TreeRisk_class_summary_BEFORE.csv\n",
      "- G:\\Shared drives\\Wellcome Trust Project Data\\1_preprocess\\UrbanCoolingModel\\EP_preliminary_tests\\clipped_lulc\\UKECH\\LCM2023_London_10m_clip2aoi_tcc24_scenario3_TreeRisk_class_summary_AFTER.csv\n"
     ]
    }
   ],
   "source": [
    "# load function to use in notebook\n",
    "from function_summarize_lc_classes import summarize_lc_classes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ---- Compute pixel area if projected (optional) ----\n",
    "px_area_m2 = None\n",
    "if lc_crs and lc_crs.is_projected:\n",
    "    # rasterio Affine: transform.a = pixel width, transform.e = pixel height (negative)\n",
    "    px_area_m2 = abs(transform.a) * abs(transform.e)\n",
    "\n",
    "# ---- Summaries: BEFORE (original) and AFTER (remapped) ----\n",
    "summary_before = summarize_lc_classes(\n",
    "    arr,\n",
    "    land_cover_labels,\n",
    "    nodata=0,  # Use 0 if it is the nodata value in the original raster\n",
    "    px_area_m2=px_area_m2,\n",
    "    sort_by=\"class\"\n",
    ")\n",
    "\n",
    "# Optional: if you defined land_cover_labels_scenario; otherwise reuse land_cover_labels\n",
    "labels_after = globals().get(\"land_cover_labels_scenario\", land_cover_labels)\n",
    "\n",
    "summary_after = summarize_lc_classes(\n",
    "    remapped,\n",
    "    labels_after,\n",
    "    nodata=0,\n",
    "    px_area_m2=px_area_m2,\n",
    "    sort_by=\"class\"\n",
    ")\n",
    "\n",
    "print(\"\\n=== Class proportions BEFORE scenario ===\")\n",
    "print(summary_before.to_string(index=False))\n",
    "\n",
    "print(\"\\n=== Class proportions AFTER scenario ===\")\n",
    "print(summary_after.to_string(index=False))\n",
    "\n",
    "# ---- Optional: save to CSV ----\n",
    "out_csv_before = lc_output.replace(\".tif\", \"_class_summary_BEFORE.csv\")\n",
    "out_csv_after  = lc_output.replace(\".tif\", \"_class_summary_AFTER.csv\")\n",
    "summary_before.to_csv(out_csv_before, index=False)\n",
    "summary_after.to_csv(out_csv_after, index=False)\n",
    "print(f\"\\nSaved summaries:\\n- {out_csv_before}\\n- {out_csv_after}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: G:\\Shared drives\\Wellcome Trust Project Data\\1_preprocess\\UrbanCoolingModel\\EP_preliminary_tests\\clipped_lulc\\UKECH\\LCM2023_London_10m_clip2aoi_tcc24_scenario3_TreeRisk_class_summary_CHANGE.csv\n",
      "\n",
      "=== Class proportions changed ===\n",
      " class_code  area_km2_before  area_km2_after  area_km2_change\n",
      "          1             8.16            8.01            -0.15\n",
      "          2             1.18            1.16            -0.02\n",
      "          3            57.05           57.05             0.00\n",
      "          4           281.48          306.09            24.61\n",
      "          5             0.00            0.00             0.00\n",
      "          6             4.14            4.14             0.00\n",
      "          8             3.15            3.15             0.00\n",
      "          9             0.09            0.09             0.00\n",
      "         10             0.48            0.48             0.00\n",
      "         12             1.29            1.29             0.00\n",
      "         13             1.10            1.10             0.00\n",
      "         14            32.67           32.67             0.00\n",
      "         16             0.04            0.04             0.00\n",
      "         18             0.21            0.21             0.00\n",
      "         19             0.87            0.87             0.00\n",
      "         20           491.11          491.11             0.00\n",
      "         21           400.53          400.53             0.00\n",
      "        100           311.14          286.70           -24.44\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## compute the change in area_km2 ------------------------------------------------------------------ \n",
    "import pandas as pd\n",
    "\n",
    "# Read\n",
    "df_before = pd.read_csv(out_csv_before)\n",
    "df_after  = pd.read_csv(out_csv_after)\n",
    "\n",
    "# Keep only what we need and rename\n",
    "b = df_before[['class_code', 'area_km2']].rename(columns={'area_km2': 'area_km2_before'})\n",
    "a = df_after [['class_code', 'area_km2']].rename(columns={'area_km2': 'area_km2_after'})\n",
    "\n",
    "# Outer join on class_code\n",
    "merged = b.merge(a, on='class_code', how='outer')\n",
    "\n",
    "# Ensure numeric, then compute change\n",
    "for c in ['area_km2_before', 'area_km2_after']:\n",
    "    merged[c] = pd.to_numeric(merged[c], errors='coerce')\n",
    "\n",
    "merged['area_km2_change'] = merged['area_km2_after'].fillna(0) - merged['area_km2_before'].fillna(0)\n",
    "\n",
    "# Save\n",
    "out_csv_change = lc_output.replace(\".tif\", \"_class_summary_CHANGE.csv\")\n",
    "merged.to_csv(out_csv_change, index=False)\n",
    "print(f\"Saved: {out_csv_change}\")\n",
    "\n",
    "print(\"\\n=== Class proportions changed ===\")\n",
    "print(merged.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
