---
title: "Untitled"
output: html_document
date: "2025-09-21"
---


## Setup

```{r include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(readr)
library(dplyr)
library(tidyr)
library(stringr)

library(tmap)
```


## Load data

  Download data from [UK's Office for National Statistics](https://www.nomisweb.co.uk/datasets/mortsa)
  
  Be sure to download data using "Database - Tab separated values (.tsv)"


```{r - df}

f_data <- '387056911188607_data.tsv'
f_geog <- '387056911188607_geog.tsv'

f_data <- '842881776194293_data.tsv' # updated on 1/19/2026
f_geog <- '842881776194293_geog.tsv'
  
# read TSV
f <- file.path('./data/health-data', f_data)
df <- read_tsv(f, show_col_types = FALSE) %>%
  as.data.frame() %>%
  rename_all(tolower)

df_dup <- df %>%
  group_by(geogcode) %>%
  filter(n() > 1) %>%
  ungroup()

df_sub <- df %>%
  dplyr::filter(date == 2023) %>%
  dplyr::filter(str_starts(geogcode, "E09"))


df_uni <- df %>%
  distinct_all() %>%
  as.data.frame()

names(df_uni)
unique(df_uni$`cause of deat`)
unique(df_uni$date)
yr_min <- min(unique(df_uni$date)); yr_min
```




```{r - geo}
f <- file.path('./data/health-data', f_geog)
df_geo <- read_tsv(f, show_col_types = FALSE) %>%
  separate_wider_delim(description, delim = ":", 
                       names = c("area_code", "area_name"), 
                       too_few = "align_start", cols_remove = F) %>%
  distinct(geogcode, description, .keep_all = T) %>%
  as.data.frame()

df_geo_dup <- df_geo %>%
  group_by(geogcode) %>%
  filter(n() > 1) %>%
  ungroup()


df_geo_unique <- df_geo %>%
  distinct(geogcode, .keep_all = T) %>%
  as.data.frame()


unique(df_geo_unique$area_code)

geo_lacu <- df_geo_unique %>%
  filter(area_code == 'lacu2023') %>%
  select(-description) %>%
  as.data.frame()
```


```{r - geo - shp}

library(sf)
f <- file.path('./data/01_raw/statistical-gis-boundaries-london/ESRI', 'London_Borough_Excluding_MHW.shp')
gla_bor <- st_read(f) %>%
  select(-any_of(c("SUB_2009", "SUB_2006" )))
names(gla_bor)
plot(gla_bor[1])



## merge lacu code with sf data -- perfect match
geo_bor_sf <- gla_bor %>%
  left_join(., geo_lacu, by = c('GSS_CODE' = 'geogcode'))
```


```{r - merge}
unique(df_uni$flag)

df_uni_geo_comb <- df_uni %>%
  left_join(., df_geo_unique, by = 'geogcode') %>%
  select(-flag, -description) %>%
  as.data.frame()

unique(df_uni_geo_comb$area_code)



## filter borough data
dat_bor <- df_uni_geo_comb %>%
  dplyr::filter(area_code == 'lacu2023') %>%
  pivot_wider(names_from = 'cause of death', values_from = 'value')



dat_london <- df_uni_geo_comb %>%
  filter(area_code == 'gor') %>%
  as.data.frame()
```


```{r - merge - save}

## save data ------------------

f <- file.path('./data/health-data/_processed', 'dat_mortality_london_borough.RDS')
saveRDS(object = dat_bor, file = f)
  
f <- file.path('./data/health-data/_processed', 'dat_mortality_london_city.RDS')
saveRDS(object = dat_london, file = f)
```



  use `c4a_gui()` to find proper colors
  
```{r - viz - loop plot by yr, eval=FALSE, include=FALSE}

# yr = 2023

yr_list <- unique(dat_bor$date)
yr_list


## filter health indicator
names(dat_bor)


icd10_selected <- "";            icd_postfix = ''
icd10_selected <- "i00|j00|x60"; icd_postfix = 'selected'
icd10_selected <- "a00|i20|i60|j00|x60"; icd_postfix = 'selected4'

# Split the string by the pipe "|"
prefixes <- unlist(strsplit(icd10_selected, "\\|"))

dat_bor_select <- dat_bor %>%
  select(1:area_name, starts_with(prefixes, ignore.case = TRUE))


## loop 
for (yr in yr_list) {
  dat <- dat_bor_select %>%
    filter(date == yr) %>%
    left_join(gla_bor, ., by = c('GSS_CODE' = 'geogcode'))
  

  # Example: pivot columns into long format
  dat_ <- dat %>%
    pivot_longer(cols = matches(icd10_selected),
                 names_to = "ind",
                 values_to = "number")
  
  # determine figure size
  if (nchar(icd10_selected) > 1) {
    dat_long <- dat_ %>%
      filter(str_detect(ind, regex(paste0("^(", icd10_selected, ")"), ignore_case = TRUE)))
    fig.height = 4.5
  } else {
    dat_long <- dat_
    fig.height = 9/2
  }
  
  # Plot faceted maps
  map <- 
    tm_shape(dat_long) +
    tm_polygons("number", 
                # palette = "Reds", 
                fill.scale = tm_scale(values = "brewer.oranges"),
                fill.free = T) +
    tm_facets(by = "ind", columns = 2) +
    tm_layout(legend.show = TRUE,
              legend.outside = FALSE, component.autoscale = F, 
              # overall ‘scale’ of the map (all line widths, point sizes and font sizes)
              scale = 0.8,
              # shrink legend
              legend.text.size  = .6,   # shrink legend labels
              legend.title.size = .8,   # shrink legend title
              
              ## continuous legends are treated as histograms/colorbars
              legend.hist.height = 0.4,  # for continuous color scales
              legend.hist.width  = 0.5,
              # legend.width      = 2,   # shrink legend box width
              # legend.height     = 3,   # shrink legend box height
              
              # inner.margins = c(top, left, bottom, right)
              inner.margins = c(0.01, 0.01, 0.01, 0.2),  # extra space on right
              legend.frame = F, 
  
              legend.position = c("right", "bottom"))
  
  # Save as PNG
  f <- paste0("./figures/health_", icd_postfix, '_', yr, "_v2.png")
  tmap_save(tm = map, filename = f, width = 7, height = fig.height, units = "in", dpi = 300)

}
```



```{r - model input -> raster}

yr <- 2021


resolution_target = 10 # meters


dat <- dat_bor %>%
  filter(date == yr) %>%
  left_join(gla_bor, ., by = c('GSS_CODE' = 'geogcode')) %>%
  pivot_longer(cols = 13:20, names_to = 'ind', values_to = 'death_case') %>%
  mutate(
    # 1 hectare = 10,000 m²
    cases_per_m2 = death_case / (HECTARES * 10000),
    cases_per_px = cases_per_m2 * (resolution_target^2) 
  ) 

dat_w <- dat %>%
  select(-death_case, -cases_per_m2) %>%
  pivot_wider(names_from = 'ind', values_from = 'cases_per_px')

# Check structure to verify column positions
str(dat_w)
names(dat_w)
message("Columns: \n", paste(names(dat_w)[14:21], collapse = "\n"))


## Convert to raster at 10m resolution
# Load packages
library(sf)
library(terra)


# --- Data preparation ---
# Ensure sf and project to British National Grid
dat_bng <- st_transform(dat_w, 27700)  # EPSG:27700

# ======== Columns to rasterize (13-18) ========
vars <- names(dat_w)[14:21]
message("Rasterizing these columns:\n  - ", paste(vars, collapse = "\n  - "))

# ---- Data cleaning ----
clean_to_numeric <- function(x) {
  # Handle units
  if (inherits(x, "units")) x <- units::drop_units(x)
  # Handle list columns
  if (is.list(x)) x <- unlist(x, use.names = FALSE)
  # Convert to character first for consistent processing
  x_char <- as.character(x)
  # Remove commas (thousands separators) and trim whitespace
  x_char <- gsub(",", "", trimws(x_char))
  # Convert to numeric, handling NA conversions
  suppressWarnings(as.numeric(x_char))
}

# Apply cleaning only to the target variables
dat_bng <- dat_bng %>%
  mutate(across(all_of(vars), clean_to_numeric))

# Check for excessive NAs after conversion
na_counts <- sapply(vars, function(col) sum(is.na(dat_bng[[col]])))
message("NA counts after conversion:\n", 
        paste(paste0("  - ", vars, ": ", na_counts), collapse = "\n"))

# Convert to SpatVector
v_bng <- terra::vect(dat_bng)

# ======== Template Raster ========
r_tmpl <- terra::rast(v_bng, resolution = resolution_target)

# Output folder
out_dir <- "G:/Shared drives/Wellcome Trust Project Data/1_preprocess/UrbanCoolingModel/OfficialWorkingInputs/health_rasters_10m_bng"  
# Fixed leading dot
if (!dir.exists(out_dir)) dir.create(out_dir, recursive = TRUE)

# ======== Safe naming function ========
safe_name <- function(x) {
  # Remove special characters, replace spaces with underscores
  nm <- gsub("[^a-zA-Z0-9._]", "_", x)
  nm <- gsub("_+", "_", nm)  # Collapse multiple underscores
  nm <- gsub("^_|_$", "", nm)  # Remove leading/trailing underscores
  tolower(nm)  # Optional: convert to lowercase for consistency
}


# Set PROJ library path (add this before any spatial operations)
if (Sys.getenv("PROJ_LIB") == "") {
  Sys.setenv(PROJ_LIB = system.file("proj", package = "terra"))
}

if (Sys.getenv("GDAL_DATA") == "") {
  Sys.setenv(GDAL_DATA = system.file("gdal", package = "terra"))
}


# ======== Rasterize each variable ========
rasters <- list()

for (col in vars) {
  message("Processing: ", col)
  
  # Ensure the column is numeric
  if (!is.numeric(v_bng[[col]])) {
    v_bng[[col]] <- clean_to_numeric(v_bng[[col]])
  }
  
  # Rasterize
  r <- terra::rasterize(
    v_bng,         # Source vector data (polygons with attributes)
    r_tmpl,        # Target raster template (empty grid)
    field = col,   # Which attribute column to use
    # How to handle multiple polygons overlapping one raster cell
    fun = "mean",  # How to aggregate values
    na.rm = TRUE,  # Handle missing values
    touches = TRUE # How to treat edge cells
  )
  
  # Create safe filename
  safe_col <- safe_name(col)
  filename <- paste0(safe_col, "_bng10m_", yr, ".tif")
  output_path <- file.path(out_dir, filename)
  
  # Write raster
  terra::writeRaster(r, output_path, overwrite = TRUE)
  
  # Store in list
  rasters[[safe_col]] <- r
  
  message("Saved: ", filename)
}

# ======== Completion message ========
message("All ", length(vars), " rasters written to: ", normalizePath(out_dir))
message("Rasters created: \n", paste(names(rasters), collapse = ", \n"))
```

