{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Environment Info ===\n",
      "Python envi    : c:\\Users\\pc\\.conda\\envs\\geo_env\\python.exe\n",
      "Python version : 3.11.13\n",
      "Platform       : Windows-10-10.0.22631-SP0\n",
      "geopandas      : 0.14.4\n",
      "numpy          : 2.2.6\n",
      "matplotlib     : 3.10.6\n",
      "========================\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import sys, platform\n",
    "print(\"=== Environment Info ===\")\n",
    "print(f\"Python envi    : {sys.executable}\")\n",
    "print(f\"Python version : {sys.version.split()[0]}\")\n",
    "print(f\"Platform       : {platform.platform()}\")\n",
    "print(f\"geopandas      : {gpd.__version__}\")\n",
    "print(f\"numpy          : {np.__version__}\")\n",
    "print(f\"matplotlib     : {plt.matplotlib.__version__}\")\n",
    "print(\"========================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Set the working directory\n",
    "wd_main     = Path(r\"G:\\Shared drives\\Wellcome Trust Project Data\") \n",
    "wd_shp      = wd_main / \"1_preprocess\" / \"UrbanCoolingModel\" / \"OfficialWorkingInputs\" / \"AOIs\"\n",
    "dir_ucm_out = wd_main / \"2_postprocess_intermediate\" / \"UCM_official_runs\"\n",
    "figures_dir = wd_main / \"3_final\" / \"UCM_figures\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AOI - select one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. borough level AOI files\n",
    "admin_shapefile = wd_shp / \"London_Borough_aoi.shp\"  # Administrative boundary (e.g., census tracts)\n",
    "aoi_adm = gpd.read_file(admin_shapefile)\n",
    "\n",
    "\n",
    "\n",
    "# 2. LSOA level AOI files\n",
    "admin_shapefile = wd_shp / \"Social_Vulnerability_Index_london_q.gpkg\"  # LSOA boundary\n",
    "aoi_adm = gpd.read_file(admin_shapefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Energy results - Building level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\Shared drives\\Wellcome Trust Project Data\\2_postprocess_intermediate\\UCM_official_runs\\scenario0\\work_and_energy_runs\\buildings_with_stats_london_scenario_25.0deg_2.0uhi_45.0hum_energy_productivity.shp\n",
      "G:\\Shared drives\\Wellcome Trust Project Data\\2_postprocess_intermediate\\UCM_official_runs\\scenario0\\work_and_energy_runs\\buildings_with_stats_london_scenario_25.0deg_5.0uhi_45.0hum_energy_productivity.shp\n",
      "G:\\Shared drives\\Wellcome Trust Project Data\\2_postprocess_intermediate\\UCM_official_runs\\scenario0\\work_and_energy_runs\\buildings_with_stats_london_scenario_28deg_2uhi_45hum_energy_productivity.shp\n",
      "G:\\Shared drives\\Wellcome Trust Project Data\\2_postprocess_intermediate\\UCM_official_runs\\scenario0\\work_and_energy_runs\\buildings_with_stats_london_scenario_28deg_5uhi_45hum_energy_productivity.shp\n",
      "G:\\Shared drives\\Wellcome Trust Project Data\\2_postprocess_intermediate\\UCM_official_runs\\scenario1\\work_and_energy_runs\\buildings_with_stats_london_scenario_25.0deg_2.0uhi_45.0hum_energy_productivity.shp\n",
      "G:\\Shared drives\\Wellcome Trust Project Data\\2_postprocess_intermediate\\UCM_official_runs\\scenario1\\work_and_energy_runs\\buildings_with_stats_london_scenario_25.0deg_5.0uhi_45.0hum_energy_productivity.shp\n",
      "G:\\Shared drives\\Wellcome Trust Project Data\\2_postprocess_intermediate\\UCM_official_runs\\scenario1\\work_and_energy_runs\\buildings_with_stats_london_scenario_28deg_2uhi_45hum_energy_productivity.shp\n",
      "G:\\Shared drives\\Wellcome Trust Project Data\\2_postprocess_intermediate\\UCM_official_runs\\scenario1\\work_and_energy_runs\\buildings_with_stats_london_scenario_28deg_5uhi_45hum_energy_productivity.shp\n",
      "G:\\Shared drives\\Wellcome Trust Project Data\\2_postprocess_intermediate\\UCM_official_runs\\scenario2\\work_and_energy_runs\\buildings_with_stats_london_scenario_25.0deg_5.0uhi_45.0hum_energy_productivity.shp\n",
      "G:\\Shared drives\\Wellcome Trust Project Data\\2_postprocess_intermediate\\UCM_official_runs\\scenario2\\work_and_energy_runs\\buildings_with_stats_london_scenario_25deg_2uhi_45hum_energy_productivity.shp\n",
      "G:\\Shared drives\\Wellcome Trust Project Data\\2_postprocess_intermediate\\UCM_official_runs\\scenario2\\work_and_energy_runs\\buildings_with_stats_london_scenario_28deg_2uhi_45hum_energy_productivity.shp\n",
      "G:\\Shared drives\\Wellcome Trust Project Data\\2_postprocess_intermediate\\UCM_official_runs\\scenario2\\work_and_energy_runs\\buildings_with_stats_london_scenario_28deg_5uhi_45hum_energy_productivity.shp\n",
      "G:\\Shared drives\\Wellcome Trust Project Data\\2_postprocess_intermediate\\UCM_official_runs\\scenario3\\work_and_energy_runs\\buildings_with_stats_london_scenario3_25.0deg_5.0uhi_45hum_energy_productivity.shp\n",
      "G:\\Shared drives\\Wellcome Trust Project Data\\2_postprocess_intermediate\\UCM_official_runs\\scenario3\\work_and_energy_runs\\buildings_with_stats_london_scenario3_28deg_2uhi_45hum_energy_productivity.shp\n",
      "G:\\Shared drives\\Wellcome Trust Project Data\\2_postprocess_intermediate\\UCM_official_runs\\scenario3\\work_and_energy_runs\\buildings_with_stats_london_scenario3_28deg_5uhi_45hum_energy_productivity.shp\n",
      "G:\\Shared drives\\Wellcome Trust Project Data\\2_postprocess_intermediate\\UCM_official_runs\\scenario3\\work_and_energy_runs\\buildings_with_stats_london_scenario_25.0deg_2.0uhi_45.0hum_energy_productivity.shp\n",
      "G:\\Shared drives\\Wellcome Trust Project Data\\2_postprocess_intermediate\\UCM_official_runs\\scenario41\\work_and_energy_runs\\tcc_10prc\\buildings_with_stats_london_scenario4_10prc_25deg_2uhi_45hum_energy_productivity.shp\n",
      "G:\\Shared drives\\Wellcome Trust Project Data\\2_postprocess_intermediate\\UCM_official_runs\\scenario41\\work_and_energy_runs\\tcc_10prc\\buildings_with_stats_london_scenario4_10prc_25deg_5uhi_45hum_energy_productivity.shp\n",
      "G:\\Shared drives\\Wellcome Trust Project Data\\2_postprocess_intermediate\\UCM_official_runs\\scenario41\\work_and_energy_runs\\tcc_10prc\\buildings_with_stats_london_scenario4_10prc_28deg_2uhi_45hum_energy_productivity.shp\n",
      "G:\\Shared drives\\Wellcome Trust Project Data\\2_postprocess_intermediate\\UCM_official_runs\\scenario41\\work_and_energy_runs\\tcc_10prc\\buildings_with_stats_london_scenario4_10prc_28deg_5uhi_45hum_energy_productivity.shp\n",
      "G:\\Shared drives\\Wellcome Trust Project Data\\2_postprocess_intermediate\\UCM_official_runs\\scenario42\\work_and_energy_runs\\tcc_20prc\\buildings_with_stats_london_scenario4_20prc_25.0deg_2.0uhi_45.0hum_energy_productivity.shp\n",
      "G:\\Shared drives\\Wellcome Trust Project Data\\2_postprocess_intermediate\\UCM_official_runs\\scenario42\\work_and_energy_runs\\tcc_20prc\\buildings_with_stats_london_scenario4_20prc_25.0deg_5.0uhi_45.0hum_energy_productivity.shp\n",
      "G:\\Shared drives\\Wellcome Trust Project Data\\2_postprocess_intermediate\\UCM_official_runs\\scenario42\\work_and_energy_runs\\tcc_20prc\\buildings_with_stats_london_scenario4_20prc_28deg_2uhi_45hum_energy_productivity.shp\n",
      "G:\\Shared drives\\Wellcome Trust Project Data\\2_postprocess_intermediate\\UCM_official_runs\\scenario42\\work_and_energy_runs\\tcc_20prc\\buildings_with_stats_london_scenario4_20prc_28deg_5uhi_45hum_energy_productivity.shp\n",
      "G:\\Shared drives\\Wellcome Trust Project Data\\2_postprocess_intermediate\\UCM_official_runs\\scenario43\\work_and_energy_runs\\tcc_30prc\\buildings_with_stats_london_scenario4_30prc_25.0deg_2.0uhi_45.0hum_energy_productivity.shp\n",
      "G:\\Shared drives\\Wellcome Trust Project Data\\2_postprocess_intermediate\\UCM_official_runs\\scenario43\\work_and_energy_runs\\tcc_30prc\\buildings_with_stats_london_scenario4_30prc_25.0deg_5.0uhi_45.0hum_energy_productivity.shp\n",
      "G:\\Shared drives\\Wellcome Trust Project Data\\2_postprocess_intermediate\\UCM_official_runs\\scenario43\\work_and_energy_runs\\tcc_30prc\\buildings_with_stats_london_scenario4_30prc_28deg_2uhi_45hum_energy_productivity.shp\n",
      "G:\\Shared drives\\Wellcome Trust Project Data\\2_postprocess_intermediate\\UCM_official_runs\\scenario43\\work_and_energy_runs\\tcc_30prc\\buildings_with_stats_london_scenario4_30prc_28deg_5uhi_45hum_energy_productivity.shp\n"
     ]
    }
   ],
   "source": [
    "\n",
    "var = \"energy_sav\" # heavy work\n",
    "\n",
    "\n",
    "# 2) Recursive: all files in subfolders too\n",
    "files = sorted(dir_ucm_out.rglob(\"buildings_with_stats_london_scenario*.shp\"))\n",
    "\n",
    "# for p in files:\n",
    "#     print(p)\n",
    "\n",
    "# subset filenames that contain \"25\" or \"28\" anywhere in the name\n",
    "fs = [f for f in files if (\"25\" in f.name) or (\"28\" in f.name)]\n",
    "\n",
    "for p in fs:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "quickly check the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import geopandas as gpd\n",
    "\n",
    "# # 1. Pick the first file from your list\n",
    "# sample_file = fs[0]\n",
    "# print(f\"Inspecting file: {sample_file.name}\")\n",
    "\n",
    "# # 2. Read only the first row (much faster than reading the whole file)\n",
    "# gdf_sample = gpd.read_file(sample_file, rows=1)\n",
    "\n",
    "# # 3. Print the column names\n",
    "# print(\"\\nColumn Names:\")\n",
    "# for col in gdf_sample.columns:\n",
    "#     print(f\" - {col}\")\n",
    "\n",
    "# print(gdf_sample.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing scenario: scenario0\n"
     ]
    }
   ],
   "source": [
    "# # Get all parts of the path\n",
    "# p = fs[0]\n",
    "# parts = p.parts \n",
    "\n",
    "# # Find the index of the base folder\n",
    "# if \"UCM_official_runs\" in parts:\n",
    "#     idx = parts.index(\"UCM_official_runs\")\n",
    "#     scenario_name = parts[idx + 1] # Take the folder right after it\n",
    "# else:\n",
    "#     scenario_name = \"unknown_scenario\"\n",
    "\n",
    "# print(f\"Processing scenario: {scenario_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### covert shp to raster -> zonal stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LSOA base layer...\n",
      "Index(['LSOA_CODE', 'Neighborhood_name', 'metric_category',\n",
      "       'pIncomeDeprivation', 'p5under', 'p75over', 'pNotEnglishProficient',\n",
      "       'pSocial_housing', 'pBAME', 'pIncomeDeprivation_pct', 'p5under_pct',\n",
      "       'p75over_pct', 'pNotEnglishProficient_pct', 'pSocial_housing_pct',\n",
      "       'pBAME_pct', 'mean_Social', 'mean_Household', 'mean_Racial',\n",
      "       'mean_Housing', 'overall_score', 'overall_pct', 'overall_rank',\n",
      "       'pIncomeDeprivation_q', 'p5under_q', 'p75over_q',\n",
      "       'pNotEnglishProficient_q', 'pSocial_housing_q', 'pBAME_q', 'geometry'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio import features\n",
    "from rasterio.transform import from_bounds\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# --- 1. Configuration ---\n",
    "# Define paths\n",
    "LSOA_PATH = admin_shapefile\n",
    "OUTPUT_DIR = dir_ucm_out / \"zonal_stats_lsoa\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Which column in the building shapefiles contains the value you want to aggregate?\n",
    "VALUE_COL = \"energy_sav\" \n",
    "RESOLUTION = 30 # 30 meter resolution\n",
    "\n",
    "# Setup file list (from your snippet) - fs is already defined above\n",
    "\n",
    "\n",
    "# --- 2. Prepare the Reference Grid (LSOA) ---\n",
    "print(\"Loading LSOA base layer...\")\n",
    "lsoa = gpd.read_file(LSOA_PATH, engine=\"pyogrio\")\n",
    "# Rename 'id' to 'LSOA_CODE'\n",
    "lsoa = lsoa.rename(columns={'id': 'LSOA_CODE'})\n",
    "print(lsoa.columns)\n",
    "\n",
    "# Keep only necessary columns to keep memory usage low\n",
    "# Ensure 'LSOA_CODE' is the unique identifier\n",
    "lsoa_base = lsoa.copy() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### point approach "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Process Each File ---\n",
    "for p in fs:\n",
    "    # A. Extract Scenario and Clean Name\n",
    "    try:\n",
    "        scenario_name = p.parent.parent.name # Parent of parent folder\n",
    "    except:\n",
    "        scenario_name = \"unknown_scenario\"\n",
    "        \n",
    "    clean_stem = p.stem.replace(\"buildings_with_stats_london_\", \"\").replace(\"_energy_productivity\", \"\")\n",
    "    \n",
    "    print(f\"Processing: {scenario_name} | {clean_stem}\")\n",
    "\n",
    "    # B. Load Buildings (Only Geometry and Energy Column)\n",
    "    try:\n",
    "        bldgs = gpd.read_file(p, engine=\"pyogrio\", columns=['energy_sav', 'geometry'])\n",
    "    except Exception as e:\n",
    "        print(f\"  Error reading file: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Align CRS\n",
    "    if bldgs.crs != lsoa_base.crs:\n",
    "        bldgs = bldgs.to_crs(lsoa_base.crs)\n",
    "\n",
    "    # C. Convert to Centroids (Crucial Step)\n",
    "    # This turns polygons into points. It's much faster to join points to polygons.\n",
    "    # It ensures every building is counted, even if they are tiny or close together.\n",
    "    bldgs['geometry'] = bldgs.geometry.centroid\n",
    "\n",
    "    # D. Spatial Join (Assign every building to an LSOA)\n",
    "    # predicate='within' checks which LSOA the building point is inside\n",
    "    joined = gpd.sjoin(bldgs, lsoa_base, how=\"inner\", predicate=\"within\")\n",
    "\n",
    "    # E. Calculate Statistics (GroupBy LSOA)\n",
    "    stats = joined.groupby('LSOA_CODE')['energy_sav'].agg(['sum', 'mean', 'count']).reset_index()\n",
    "    \n",
    "    # # Rename columns for clarity\n",
    "    # stats.columns = ['LSOA_CODE', 'energy_sav_sum', 'energy_sav_mean', 'bldg_count']\n",
    "\n",
    "    # Rename columns for clarity\n",
    "    stats = stats.rename(columns={'sum': 'energy_sav_sum', 'mean': 'energy_sav_mean', 'count': 'bldg_count'})\n",
    "\n",
    "    # F. Merge Results back to LSOA Geometry\n",
    "    result_gdf = lsoa_base.merge(stats, on='LSOA_CODE', how='left')\n",
    "\n",
    "    # Fill NaNs (LSOAs that had no buildings) with 0\n",
    "    cols_to_fill = ['energy_sav_sum', 'energy_sav_mean', 'bldg_count']\n",
    "    result_gdf[cols_to_fill] = result_gdf[cols_to_fill].fillna(0)\n",
    "\n",
    "    # Add Metadata\n",
    "    result_gdf['scenario'] = scenario_name\n",
    "\n",
    "    # G. Save\n",
    "    out_name = f\"{scenario_name}_{clean_stem}_energy_stats.gpkg\"\n",
    "    out_path = OUTPUT_DIR / out_name\n",
    "    \n",
    "    print(f\"  Saving to {out_path}...\")\n",
    "    result_gdf.to_file(out_path, driver=\"GPKG\")\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raster approach\n",
    "\n",
    "Rasterizing shp to 30m Resolution\n",
    "- For \"Sum\" calculations (energy_sav), rasterizing at 30m is dangerous if your buildings are smaller than 900m² (which most London houses are).\n",
    "- The Problem: If 3 small row houses fit inside one 30m pixel, the rasterization process will typically only capture the value of one of them (the last one processed). You will lose the data for the other two.\n",
    "- The Result: Your Total Sum of energy savings will be significantly undercounted.\n",
    "\n",
    "\n",
    "The Better Solution: Vector \"Centroid\" Method: \n",
    "- Since you ultimately want the result as a GPKG table (LSOA zones), you should skip the raster step entirely.\n",
    "- Instead, convert the buildings to Points (Centroids) and perform a Spatial Join.\n",
    "- It is 100% accurate for Sums (no overlapping pixels).\n",
    "- It is faster than rasterizing at high resolution.\n",
    "- It handles the \"Scenario\" extraction you requested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Define 30m Grid based on LSOA bounds\n",
    "# xmin, ymin, xmax, ymax = lsoa.total_bounds\n",
    "# width = int((xmax - xmin) / RESOLUTION)\n",
    "# height = int((ymax - ymin) / RESOLUTION)\n",
    "# transform = from_bounds(xmin, ymin, xmax, ymax, width, height)\n",
    "\n",
    "# print(f\"Grid dimensions: {width}x{height} (30m resolution)\")\n",
    "\n",
    "# # Rasterize LSOAs to create a \"Zone Map\" (ID for every pixel)\n",
    "# print(\"Rasterizing LSOA zones...\")\n",
    "# lsoa['temp_idx'] = range(len(lsoa))\n",
    "# lsoa_shapes = ((geom, val) for geom, val in zip(lsoa.geometry, lsoa['temp_idx']))\n",
    "\n",
    "# # Fill with -1 for areas outside any LSOA\n",
    "# lsoa_grid = features.rasterize(\n",
    "#     shapes=lsoa_shapes,\n",
    "#     out_shape=(height, width),\n",
    "#     transform=transform,\n",
    "#     fill=-1, \n",
    "#     dtype='int32'\n",
    "# )\n",
    "\n",
    "# # Flatten LSOA grid for fast indexing\n",
    "# flat_lsoa = lsoa_grid.ravel()\n",
    "\n",
    "# # --- 3. Process Each Scenario File ---\n",
    "# for p in fs:\n",
    "#     print(f\"Processing: {p.name}\")\n",
    "\n",
    "#     # Get scenario name from path -------\n",
    "#     parts = p.parts \n",
    "#     # Find the index of the base folder\n",
    "#     if \"UCM_official_runs\" in parts:\n",
    "#         idx = parts.index(\"UCM_official_runs\")\n",
    "#         scenario_name = parts[idx + 1] # Take the folder right after it\n",
    "#     else:\n",
    "#         scenario_name = \"scenario_unknown\"\n",
    "    \n",
    "#     # 1. Load Building Data\n",
    "#     try:\n",
    "#         # Load only geometry and the value column to save memory\n",
    "#         bldgs = gpd.read_file(p, engine=\"pyogrio\", columns=[VALUE_COL, 'geometry'])\n",
    "#     except Exception as e:\n",
    "#         print(f\"  Error reading {p.name}: {e}\")\n",
    "#         continue\n",
    "\n",
    "#     # Align CRS if necessary\n",
    "#     if bldgs.crs != lsoa.crs:\n",
    "#         print(\"  Reprojecting buildings...\")\n",
    "#         bldgs = bldgs.to_crs(lsoa.crs)\n",
    "\n",
    "#     # 2. Rasterize the 'energy_sav' values\n",
    "#     print(f\"  Rasterizing '{VALUE_COL}'...\")\n",
    "    \n",
    "#     # Drop rows where energy_sav is NaN\n",
    "#     bldgs = bldgs.dropna(subset=[VALUE_COL])\n",
    "    \n",
    "#     # Create generator: (geometry, energy_sav_value)\n",
    "#     bldg_shapes = ((geom, val) for geom, val in zip(bldgs.geometry, bldgs[VALUE_COL]))\n",
    "\n",
    "#     # Burn values into grid. \n",
    "#     # fill=0 assumes areas with no buildings have 0 energy savings.\n",
    "#     val_grid = features.rasterize(\n",
    "#         shapes=bldg_shapes,\n",
    "#         out_shape=(height, width),\n",
    "#         transform=transform,\n",
    "#         fill=0, \n",
    "#         dtype='float32'\n",
    "#     )\n",
    "\n",
    "#     ######################\n",
    "#     # 3. Zonal Statistics (Numpy) \n",
    "#     ######################\n",
    "#     flat_vals = val_grid.ravel()\n",
    "\n",
    "#     # Create mask: Pixel must be inside an LSOA (ID != -1) AND have a building (Value != 0)\n",
    "#     # If you want to calculate the mean over the *entire* LSOA area (including empty space),\n",
    "#     # change the mask to just: mask = (flat_lsoa != -1)\n",
    "#     mask = (flat_lsoa != -1) & (flat_vals != 0)\n",
    "    \n",
    "#     valid_lsoa_ids = flat_lsoa[mask]\n",
    "#     valid_values = flat_vals[mask]\n",
    "\n",
    "#     if len(valid_values) == 0:\n",
    "#         print(f\"  Warning: No overlaps found for {p.name}\")\n",
    "#         continue\n",
    "\n",
    "#     # Count: How many building pixels per LSOA\n",
    "#     count_per_lsoa = np.bincount(valid_lsoa_ids, minlength=len(lsoa))\n",
    "    \n",
    "#     # Sum: Total energy_sav per LSOA (sum of pixel values)\n",
    "#     sum_per_lsoa = np.bincount(valid_lsoa_ids, weights=valid_values, minlength=len(lsoa))\n",
    "\n",
    "#     # Mean: Average energy_sav PER BUILDING PIXEL within the LSOA\n",
    "#     with np.errstate(divide='ignore', invalid='ignore'):\n",
    "#         mean_per_lsoa = sum_per_lsoa / count_per_lsoa\n",
    "#         mean_per_lsoa[~np.isfinite(mean_per_lsoa)] = 0 \n",
    "\n",
    "#     ######################\n",
    "#     # 4. Save Results\n",
    "#     ######################\n",
    "#     # Attach results to a clean copy of LSOA info\n",
    "#     # result_df = lsoa[['LSOA_CODE', 'LSOA_NAME', 'geometry']].copy()\n",
    "#     result_df = lsoa.copy()\n",
    "    \n",
    "#     result_df[f'{VALUE_COL}_sum'] = sum_per_lsoa\n",
    "#     result_df[f'{VALUE_COL}_mean'] = mean_per_lsoa\n",
    "#     result_df['bldg_pixel_count'] = count_per_lsoa\n",
    "    \n",
    "#     # --- CLEAN FILENAME LOGIC ---\n",
    "#     # Remove the specific unwanted strings from the original filename\n",
    "#     clean_stem = p.stem.replace(\"with_stats_london_\", \"\").replace(\"_energy_productivity\", \"\")\n",
    "    \n",
    "#     # Construct final output name\n",
    "#     out_name = scenario_name + clean_stem + \"_energy_stats.gpkg\"\n",
    "#     out_path = OUTPUT_DIR / out_name\n",
    "    \n",
    "#     print(f\"  Saving to {out_path}...\")\n",
    "#     result_df.to_file(out_path, driver=\"GPKG\")\n",
    "\n",
    "# print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load building level data - take a long time ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the shapefile\n",
    "# f1 = dir_ucm_out / 'current_lulc' / 'work_and_energy_runs' / \"buildings_with_stats_london_scenario_22.0deg_2.0uhi_55.0hum_energy_productivity.shp\"\n",
    "# gdf_base = gpd.read_file(f1)\n",
    "# print(gdf_base.columns.tolist())\n",
    "\n",
    "# gdf_base = gdf_base.dropna(subset=[var])\n",
    "\n",
    "# print(gdf_base.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Load the shapefile\n",
    "# f2 = dir_ucm_out / 'scenario3' / 'work_and_energy_runs' / \"buildings_with_stats_london_scenario3_25.0deg_5.0uhi_45hum_energy_productivity.shp\"\n",
    "# # f2 = dir_ucm_out / 'scenario4' / 'work_and_energy_runs' / \"tcc_30prc\" / \"buildings_with_stats_london_scenario4_30prc_22.0deg_2.0uhi_55.0hum_energy_productivity.shp\"\n",
    "# gdf_new  = gpd.read_file(f2)    # Alternative scenario\n",
    "# gdf_new = gdf_new.dropna(subset=[var])\n",
    "\n",
    "\n",
    "\n",
    "# # Extract suffix\n",
    "# suffix1 = make_short_name(Path(f1), Path(dir_ucm_out) )  \n",
    "# suffix2 = make_short_name(Path(f2), Path(dir_ucm_out) )\n",
    "# suffix_change = f\"{suffix1}_VS_{suffix2}\"\n",
    "# print(suffix_change)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save a copy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # 1. Save as Feather (very fast reload in Python, good for local caching) -- will take 12 seconds\n",
    "# feather_path = dir_ucm_out / 'current_lulc' / 'work_and_energy_runs' / \"buildings_with_stats_22_2.feather\"\n",
    "# gdf_base.to_feather(feather_path)\n",
    "\n",
    "\n",
    "\n",
    "# feather_path = dir_ucm_out / 'scenario3' / 'work_and_energy_runs' / \"buildings_with_stats_25_5.feather\"\n",
    "# gdf_new.to_feather(feather_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feather_path1 = dir_ucm_out / 'current_lulc' / 'work_and_energy_runs' / \"buildings_with_stats_22_2.feather\"\n",
    "# gdf_base = pd.read_feather(feather_path1)\n",
    "\n",
    "# feather_path2 = dir_ucm_out / 'scenario3' / 'work_and_energy_runs' / \"buildings_with_stats_25_5.feather\"\n",
    "# gdf_new = pd.read_feather(feather_path2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sum by borough  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# from pathlib import Path\n",
    "\n",
    "# def make_short_name(path, base_dir) -> str:\n",
    "#     # --- normalize inputs ---\n",
    "#     # Unwrap single-element tuple/list like (path,) or [path]\n",
    "#     if isinstance(path, (tuple, list)):\n",
    "#         if len(path) == 1:\n",
    "#             path = path[0]\n",
    "#         else:\n",
    "#             raise TypeError(f\"Expected a path, got a {type(path).__name__} with len {len(path)}\")\n",
    "#     if isinstance(base_dir, (tuple, list)):\n",
    "#         if len(base_dir) == 1:\n",
    "#             base_dir = base_dir[0]\n",
    "#         else:\n",
    "#             raise TypeError(f\"Expected a base_dir path, got a {type(base_dir).__name__} with len {len(base_dir)}\")\n",
    "\n",
    "#     path = Path(path)\n",
    "#     base_dir = Path(base_dir)\n",
    "\n",
    "#     # find prefix (the first folder under base_dir, e.g. 'current_lulc' or 'scenario2')\n",
    "#     try:\n",
    "#         prefix = path.relative_to(base_dir).parts[0]\n",
    "#     except Exception:\n",
    "#         # fallback: immediate parent if not under base_dir\n",
    "#         prefix = path.parent.name\n",
    "\n",
    "#     # extract deg/uhi numbers from filename\n",
    "#     m = re.search(r\"scenario_([\\d.]+)deg_([\\d.]+)uhi\", path.name)\n",
    "#     if not m:\n",
    "#         return prefix\n",
    "\n",
    "#     deg = str(int(float(m.group(1))))\n",
    "#     uhi = str(int(float(m.group(2))))\n",
    "#     return f\"{prefix}_{deg}_{uhi}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import geopandas as gpd\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # Inputs\n",
    "# # blocks_fp = r\"path\\to\\blockgroups.shp\"    # polygons with 'ene_sav' per block group\n",
    "# tracts_fp = admin_shapefile                 # polygons\n",
    "\n",
    "# energy_col = \"energy_sav\"                   # block group total energy column\n",
    "# tract_id_col = \"GSS_CODE\"                   # tract id column in the tracts layer\n",
    "\n",
    "# # 1) Load\n",
    "# bg = gdf_base\n",
    "# # bg = gdf_new.copy()\n",
    "\n",
    "# print(bg.head(6))\n",
    "\n",
    "# tr = gpd.read_file(tracts_fp)\n",
    "\n",
    "# # 2) Project to an equal-area CRS for correct area math (US example: EPSG:5070)\n",
    "# #    Use a suitable local equal-area if you’re outside the US.\n",
    "# # ea_crs = \"EPSG:27700\"\n",
    "# # bg = bg.to_crs(ea_crs)\n",
    "# # tr = tr.to_crs(ea_crs)\n",
    "\n",
    "# # 3) Compute source polygon areas (to guard against weird or zero areas)\n",
    "# bg[\"src_area\"] = bg.geometry.area\n",
    "# bg[energy_col] = bg[energy_col].fillna(0)\n",
    "\n",
    "# # print(bg.head(6))\n",
    "\n",
    "# # 4) Intersect (overlay) to get pieces of BGs clipped by tracts\n",
    "# #    This can be memory-heavy for big areas—consider spatial indexing or tiling if needed.\n",
    "# inter = gpd.overlay(bg, tr[[tract_id_col, \"geometry\"]], how=\"intersection\")\n",
    "\n",
    "# # 5) Compute overlap area and proportional share\n",
    "# inter[\"overlap_area\"] = inter.geometry.area\n",
    "# # Avoid division by 0\n",
    "# inter = inter[inter[\"overlap_area\"] > 0].copy()\n",
    "# inter = inter[inter[\"src_area\"] > 0].copy()\n",
    "\n",
    "# # Share of the BG’s energy allocated to that tract piece\n",
    "# inter[\"ene_sav_alloc\"] = inter[energy_col] * (inter[\"overlap_area\"] / inter[\"src_area\"])\n",
    "\n",
    "# # 6) Sum by tract\n",
    "# tract_energy = (inter.groupby(tract_id_col, as_index=False)[\"ene_sav_alloc\"]\n",
    "#                         .sum()\n",
    "#                         .rename(columns={\"ene_sav_alloc\": \"ene_sav_total\"}))\n",
    "\n",
    "# # 7) Join back to tract geometry\n",
    "# tr_out = tr.merge(tract_energy, on=tract_id_col, how=\"left\")\n",
    "# tr_out[\"ene_sav_total\"] = tr_out[\"ene_sav_total\"].fillna(0)\n",
    "\n",
    "# # print(tr_out.head())\n",
    "\n",
    "# # 8) Save\n",
    "# f = Path(str(feather_path1).replace(\"energy_productivity\", \"ene_sav_total\").replace(\".shp\", \".gpkg\"))\n",
    "# tr_out.to_file(f, layer=\"tract_energy\", driver=\"GPKG\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
